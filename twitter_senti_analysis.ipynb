{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c247c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe05e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08f0160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitts</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@robbiebronniman Sounds like a great night.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damn the person who stolde my wallet !!!!!  Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greetings from the piano bench  (photo) http:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@drewryanscott i love it!! i love you!! haha f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kissthestars Pretty pretty pretty please, pak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              twitts  sentiment\n",
       "0       @robbiebronniman Sounds like a great night.           1\n",
       "1  Damn the person who stolde my wallet !!!!!  Ma...          1\n",
       "2  Greetings from the piano bench  (photo) http:/...          1\n",
       "3  @drewryanscott i love it!! i love you!! haha f...          1\n",
       "4  @kissthestars Pretty pretty pretty please, pak...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/twitter-data/master/twitt30k.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b4fe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15000\n",
       "0    15000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbff50",
   "metadata": {},
   "source": [
    "## SVM Model and Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20fc62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm(df):\n",
    "    X = df['twitts']\n",
    "    y = df['sentiment']\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X = tfidf.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "\n",
    "    print('shape of X: ', X.shape)\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print()\n",
    "    print('Printing Report')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return tfidf, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f69dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (30000, 40854)\n",
      "\n",
      "Printing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75      3000\n",
      "           1       0.74      0.75      0.75      3000\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf, clf = run_svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4215a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['i am really happy. thanks a lot for coming with me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0320bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80b61c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['i am very sad']\n",
    "clf.predict(tfidf.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6dd6b",
   "metadata": {},
   "source": [
    "## Data Cleaning and Retraining SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d463f",
   "metadata": {},
   "source": [
    "# Use our preprocess python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b74e0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/laxmimerit/preprocess_kgptalkie.git\n",
      "  Cloning https://github.com/laxmimerit/preprocess_kgptalkie.git to c:\\users\\icluster\\appdata\\local\\temp\\pip-req-build-2l9x0508\n",
      "  Resolved https://github.com/laxmimerit/preprocess_kgptalkie.git to commit 9ca68d37027af9f6a30d54640347ce3b2e2694b3\n",
      "Building wheels for collected packages: preprocess-kgptalkie\n",
      "  Building wheel for preprocess-kgptalkie (setup.py): started\n",
      "  Building wheel for preprocess-kgptalkie (setup.py): finished with status 'done'\n",
      "  Created wheel for preprocess-kgptalkie: filename=preprocess_kgptalkie-0.1.3-py3-none-any.whl size=7691 sha256=0e8889f0faa5045323357bedd0c282812f0ce7d5e49d18f892d347ade2cef65a\n",
      "  Stored in directory: C:\\Users\\ICLUSTER\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-p7n4qf94\\wheels\\d1\\c3\\bb\\559fe93e652b51cbc532f17e9693f3b70055f8560cf06c1fb3\n",
      "Successfully built preprocess-kgptalkie\n",
      "Installing collected packages: preprocess-kgptalkie\n",
      "Successfully installed preprocess-kgptalkie-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/laxmimerit/preprocess_kgptalkie.git 'C:\\Users\\ICLUSTER\\AppData\\Local\\Temp\\pip-req-build-2l9x0508'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35eb3169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\ICLUSTER\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - spacy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    catalogue-2.0.6            |   py39hcbf5309_2          32 KB  conda-forge\n",
      "    cymem-2.0.6                |   py39h415ef7b_3          34 KB  conda-forge\n",
      "    cython-blis-0.7.7          |   py39h5d4886f_1         5.6 MB  conda-forge\n",
      "    langcodes-3.3.0            |     pyhd8ed1ab_0         156 KB  conda-forge\n",
      "    murmurhash-1.0.7           |   py39h415ef7b_0          24 KB  conda-forge\n",
      "    pathy-0.6.1                |     pyhd8ed1ab_0          37 KB  conda-forge\n",
      "    preshed-3.0.6              |   py39h415ef7b_2          83 KB  conda-forge\n",
      "    pydantic-1.8.2             |   py39hb82d6ee_2         1.6 MB  conda-forge\n",
      "    shellingham-1.4.0          |     pyh44b312d_0          11 KB  conda-forge\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "    smart_open-5.2.1           |     pyhd8ed1ab_0          43 KB  conda-forge\n",
      "    spacy-3.3.0                |   py39h0f1f7c2_0         4.6 MB\n",
      "    spacy-legacy-3.0.9         |     pyhd8ed1ab_0          19 KB  conda-forge\n",
      "    spacy-loggers-1.0.2        |     pyhd8ed1ab_0          11 KB  conda-forge\n",
      "    srsly-2.4.3                |   py39h415ef7b_1         510 KB  conda-forge\n",
      "    thinc-8.0.15               |   py39hefe7e4c_0         933 KB  conda-forge\n",
      "    typer-0.4.1                |     pyhd8ed1ab_0          44 KB  conda-forge\n",
      "    typing-extensions-3.10.0.2 |       hd3eb1b0_0          12 KB\n",
      "    wasabi-0.9.1               |     pyhd8ed1ab_0          25 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        13.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  catalogue          conda-forge/win-64::catalogue-2.0.6-py39hcbf5309_2\n",
      "  cymem              conda-forge/win-64::cymem-2.0.6-py39h415ef7b_3\n",
      "  cython-blis        conda-forge/win-64::cython-blis-0.7.7-py39h5d4886f_1\n",
      "  langcodes          conda-forge/noarch::langcodes-3.3.0-pyhd8ed1ab_0\n",
      "  murmurhash         conda-forge/win-64::murmurhash-1.0.7-py39h415ef7b_0\n",
      "  pathy              conda-forge/noarch::pathy-0.6.1-pyhd8ed1ab_0\n",
      "  preshed            conda-forge/win-64::preshed-3.0.6-py39h415ef7b_2\n",
      "  pydantic           conda-forge/win-64::pydantic-1.8.2-py39hb82d6ee_2\n",
      "  shellingham        conda-forge/noarch::shellingham-1.4.0-pyh44b312d_0\n",
      "  smart_open         conda-forge/noarch::smart_open-5.2.1-pyhd8ed1ab_0\n",
      "  spacy              pkgs/main/win-64::spacy-3.3.0-py39h0f1f7c2_0\n",
      "  spacy-legacy       conda-forge/noarch::spacy-legacy-3.0.9-pyhd8ed1ab_0\n",
      "  spacy-loggers      conda-forge/noarch::spacy-loggers-1.0.2-pyhd8ed1ab_0\n",
      "  srsly              conda-forge/win-64::srsly-2.4.3-py39h415ef7b_1\n",
      "  thinc              conda-forge/win-64::thinc-8.0.15-py39hefe7e4c_0\n",
      "  typer              conda-forge/noarch::typer-0.4.1-pyhd8ed1ab_0\n",
      "  typing-extensions  pkgs/main/noarch::typing-extensions-3.10.0.2-hd3eb1b0_0\n",
      "  wasabi             conda-forge/noarch::wasabi-0.9.1-pyhd8ed1ab_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "pathy-0.6.1          | 37 KB     |            |   0% \n",
      "pathy-0.6.1          | 37 KB     | ####3      |  43% \n",
      "pathy-0.6.1          | 37 KB     | ########## | 100% \n",
      "\n",
      "spacy-3.3.0          | 4.6 MB    |            |   0% \n",
      "spacy-3.3.0          | 4.6 MB    |            |   0% \n",
      "spacy-3.3.0          | 4.6 MB    | ######3    |  63% \n",
      "spacy-3.3.0          | 4.6 MB    | ########## | 100% \n",
      "\n",
      "spacy-loggers-1.0.2  | 11 KB     |            |   0% \n",
      "spacy-loggers-1.0.2  | 11 KB     | ########## | 100% \n",
      "spacy-loggers-1.0.2  | 11 KB     | ########## | 100% \n",
      "\n",
      "preshed-3.0.6        | 83 KB     |            |   0% \n",
      "preshed-3.0.6        | 83 KB     | ########## | 100% \n",
      "preshed-3.0.6        | 83 KB     | ########## | 100% \n",
      "\n",
      "cython-blis-0.7.7    | 5.6 MB    |            |   0% \n",
      "cython-blis-0.7.7    | 5.6 MB    | #1         |  11% \n",
      "cython-blis-0.7.7    | 5.6 MB    | ########2  |  83% \n",
      "cython-blis-0.7.7    | 5.6 MB    | ########## | 100% \n",
      "\n",
      "murmurhash-1.0.7     | 24 KB     |            |   0% \n",
      "murmurhash-1.0.7     | 24 KB     | ########## | 100% \n",
      "murmurhash-1.0.7     | 24 KB     | ########## | 100% \n",
      "\n",
      "wasabi-0.9.1         | 25 KB     |            |   0% \n",
      "wasabi-0.9.1         | 25 KB     | ########## | 100% \n",
      "wasabi-0.9.1         | 25 KB     | ########## | 100% \n",
      "\n",
      "spacy-legacy-3.0.9   | 19 KB     |            |   0% \n",
      "spacy-legacy-3.0.9   | 19 KB     | ########## | 100% \n",
      "spacy-legacy-3.0.9   | 19 KB     | ########## | 100% \n",
      "\n",
      "pydantic-1.8.2       | 1.6 MB    |            |   0% \n",
      "pydantic-1.8.2       | 1.6 MB    | ########## | 100% \n",
      "pydantic-1.8.2       | 1.6 MB    | ########## | 100% \n",
      "\n",
      "smart_open-5.2.1     | 43 KB     |            |   0% \n",
      "smart_open-5.2.1     | 43 KB     | ########## | 100% \n",
      "smart_open-5.2.1     | 43 KB     | ########## | 100% \n",
      "\n",
      "typer-0.4.1          | 44 KB     |            |   0% \n",
      "typer-0.4.1          | 44 KB     | ########## | 100% \n",
      "typer-0.4.1          | 44 KB     | ########## | 100% \n",
      "\n",
      "srsly-2.4.3          | 510 KB    |            |   0% \n",
      "srsly-2.4.3          | 510 KB    | ########## | 100% \n",
      "srsly-2.4.3          | 510 KB    | ########## | 100% \n",
      "\n",
      "cymem-2.0.6          | 34 KB     |            |   0% \n",
      "cymem-2.0.6          | 34 KB     | ########## | 100% \n",
      "cymem-2.0.6          | 34 KB     | ########## | 100% \n",
      "\n",
      "thinc-8.0.15         | 933 KB    |            |   0% \n",
      "thinc-8.0.15         | 933 KB    | ########9  |  89% \n",
      "thinc-8.0.15         | 933 KB    | ########## | 100% \n",
      "\n",
      "shellingham-1.4.0    | 11 KB     |            |   0% \n",
      "shellingham-1.4.0    | 11 KB     | ########## | 100% \n",
      "\n",
      "typing-extensions-3. | 12 KB     |            |   0% \n",
      "typing-extensions-3. | 12 KB     | ########## | 100% \n",
      "typing-extensions-3. | 12 KB     | ########## | 100% \n",
      "\n",
      "catalogue-2.0.6      | 32 KB     |            |   0% \n",
      "catalogue-2.0.6      | 32 KB     | ########## | 100% \n",
      "\n",
      "langcodes-3.3.0      | 156 KB    |            |   0% \n",
      "langcodes-3.3.0      | 156 KB    | ########## | 100% \n",
      "langcodes-3.3.0      | 156 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9d13d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c072570c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.19.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: setuptools in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (58.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.62.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 16:09:02.581041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-13 16:09:02.581143: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\icluster\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.3.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3971d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import preprocess_kgptalkie as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f327dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts'] = df['twitts'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afa94578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts'] = df['twitts'].apply(lambda x: pp.cont_exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af2cb595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitts</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@robbiebronniman sounds like a great night.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>damn the person who stolde my wallet !!!!!  ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greetings from the piano bench  (photo) http:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@drewryanscott i love it!! i love you!! haha f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kissthestars pretty pretty pretty please, pak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>@calumfan1 is it in any way related to photosh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>@swiz_nz really? wow thats crap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>at the 2010 lexus hs250h press event.  again, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>@karmicunderpath ooooh now there is a nice tho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>@mariap91 i would usually ask you about the su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  twitts  sentiment\n",
       "0           @robbiebronniman sounds like a great night.           1\n",
       "1      damn the person who stolde my wallet !!!!!  ma...          1\n",
       "2      greetings from the piano bench  (photo) http:/...          1\n",
       "3      @drewryanscott i love it!! i love you!! haha f...          1\n",
       "4      @kissthestars pretty pretty pretty please, pak...          0\n",
       "...                                                  ...        ...\n",
       "29995  @calumfan1 is it in any way related to photosh...          0\n",
       "29996                   @swiz_nz really? wow thats crap           0\n",
       "29997  at the 2010 lexus hs250h press event.  again, ...          0\n",
       "29998  @karmicunderpath ooooh now there is a nice tho...          1\n",
       "29999  @mariap91 i would usually ask you about the su...          1\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c361faae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (30000, 40753)\n",
      "\n",
      "Printing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75      3000\n",
      "           1       0.75      0.76      0.75      3000\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TfidfVectorizer(), LinearSVC())"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c6f204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emails and urls\n",
    "\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_emails(x))\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_urls(x))\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_rt(x))\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_html_tags(x))\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_special_chars(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8351e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (30000, 42855)\n",
      "\n",
      "Printing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      3000\n",
      "           1       0.74      0.75      0.75      3000\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf, clf = run_svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "189ccebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am very sad']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7aec7172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad6e344",
   "metadata": {},
   "source": [
    "## Fine Tuning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56054df9",
   "metadata": {},
   "source": [
    "## Saving and Loading ML Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9f391e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d983bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('clf.pkl', 'wb'))\n",
    "pickle.dump(tfidf, open('tfidf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7fa96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del clf\n",
    "del tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bfc547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('clf.pkl', 'rb'))\n",
    "tfidf = pickle.load(open('tfidf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50717171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49d4b30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am very sad']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49d82c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076662c5",
   "metadata": {},
   "source": [
    "# Real-Time Twitter Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a74d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'R7DGimRNkT11sbngA0MRqLmNE'\n",
    "consumer_secret = 'w5Axtw43feejwgmPIhqPhPOt1aHso1Guw1yuFwlmijtlh0vguK'\n",
    "access_token = '1279486577656295425-l3gaKqKuHQdKl44rPXUc0WYcc26wgq'\n",
    "access_token_secret = '80dGAdcx6LuoWM1mSt669V5NESP0EOuX1dK8Mianjqxi2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50687cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.9.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from tweepy) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\icluster\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Installing collected packages: tweepy\n",
      "Successfully installed tweepy-4.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454fde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122e5e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweepy.models.ResultSet"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(public_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23669d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Matching Indiaâ€™s massive #talent base effectively to support the current demand environment for the $220 billion Inâ€¦ https://t.co/pnNX0TTcOF'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_tweets[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85973f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Indiaâ€™s massive #talent base effectively to support the current demand environment for the $220 billion Inâ€¦ https://t.co/pnNX0TTcOF\n",
      "RT @KirkDBorne: A Survey of #MachineLearning and #DeepLearning Applications in #Mobile &amp; Wireless Networking: https://t.co/65q0ya2G3M\n",
      "â€”â€”â€”â€”â€”â€¦\n",
      "RT @avikumart_: Day 15 #100DaysOfCode ML seriesðŸ¤–ðŸ‘‡\n",
      "\n",
      "&gt;&gt;Naive Bayes is an algorithm based on Bayesian probability. it is used for classificatiâ€¦\n",
      "RT @KirkDBorne: 50 Shades of Data\n",
      "#AI\n",
      "#Analytics\n",
      "#BI\n",
      "#BigData\n",
      "#Database\n",
      "#DataEngineering\n",
      "#DataLake\n",
      "#DataScience\n",
      "#DataWarehouse\n",
      "#DeepLearninâ€¦\n",
      "RT @Paula_Piccard: Top 100 AI Unicorns and their Success Stories: A Legendary Path\n",
      "\n",
      "Know more: https://t.co/M2pMKzLUTp\n",
      "\n",
      "#MachineLearning #Aâ€¦\n",
      "The shooting was reported shortly before 1.30 pm at Geneva Presbyterian Church in the city of Laguna Woods, the Oraâ€¦ https://t.co/kYVE6EJYvn\n",
      "RT @SourabhSKatoch: 120 Python Projects with Source Code solved and explained for free.\n",
      "\n",
      "https://t.co/HQ8RjgNMuk\n",
      "\n",
      "#DEVCommunity #MachineLeaâ€¦\n",
      "#Loans from certain institutions such as banks, government departments, and Post Offices are exempted, but cash traâ€¦ https://t.co/tn134XZJfc\n",
      "RT @IainLJBrown: Creating a Parallel Universe in an AI Lab is Possible! Real Soon - Analytics Insight\n",
      "\n",
      "Read more here: https://t.co/lCe7JgMâ€¦\n",
      "RT @sherylhyx: Excited to share that our paper \"GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed Graph Neural Netwoâ€¦\n",
      "RT @KirkDBorne: [Free PDF Download] Introduction to #Probability for Data Science: https://t.co/L51j3udY5j by @stanley_h_chan \n",
      "â€”â€”â€”â€”â€”\n",
      "#Statiâ€¦\n",
      "RT @machinelearnflx: Stanford Machine Learning course https://t.co/QUiNRwJ7dU #machinelearning #deeplearning #datascience #datascientist #dâ€¦\n",
      "RT @eighth_mile: @omarioonn ï£¿ My Turn Now; Transvestite\n",
      "#100DaysOfCode #CodeNewbie #WomenWhoCode #Programming #DataScience #AcademicTwitterâ€¦\n",
      "Watch: How members of Indian Badminton team celebrated their historic Thomas Cup win\n",
      "Track latest news updates hereâ€¦ https://t.co/5cscdHPOsi\n",
      "RT @scottmacleod: Toyota's T-HR3 Humanoid robot:\n",
      "https://t.co/nP5U6jod2u Not seeing many #HumanoidRobots around #UniversityCampuses in US &amp;â€¦\n",
      "Adani, 59, who operates India's largest commercial port and the largest renewable energy company, said he would douâ€¦ https://t.co/AqeCWaV806\n",
      "RT @JCIM_JCTC: #QuantumMechanics and #MachineLearning Synergies: Graph Attention #NeuralNetworks to Predict Chemical Reactivity  \n",
      "https://tâ€¦\n",
      "RT @rasangarocks: Python for Everybody: Exploring Data in Python 3\n",
      "\n",
      "Link - https://t.co/TeY1BTXdBD\n",
      "\n",
      "#Python #Python3 #100DaysOfCode #CodeNeâ€¦\n",
      "RT @SpirosMargaris: Robot-assisted #surgery \n",
      "\n",
      "can cut blood clot risk and speed #recovery, study finds \n",
      "\n",
      "https://t.co/c3j2PkIIhd #fintech #â€¦\n",
      "At Lumbini, the Prime Minister will visit the sacred Mayadevi temple to offer prayers.\n",
      "\n",
      "#PMModi \n",
      "https://t.co/62x9SHknoa\n"
     ]
    }
   ],
   "source": [
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06e339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
